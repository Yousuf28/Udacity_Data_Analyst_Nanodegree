{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project required to gather three datasets from three different sources and all dataset are in different format. First dataset I have downloaded programmatically from given link. I have used request library for make it easier. This data set saved as image_prediction.tsv.\n",
    "Gathering second data set was quite difficult, at least for me. I have used API for the very first time. I was stuck for long time to figure out how to do it. Anyway, with the help from instructor I was able to download the dataset. First I had to make developer account and I create key and token after that. Using the tweepy library I downloaded the data from twitter API.\n",
    "This data saved as tweet_json.txt.  Gathering third dataset was very easy though. Dataset link was given and downloaded by just one click.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess and Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First dataset was image prediction dataset. At very first that I have noticed that columns name is bit ambiguous. I like column name that are little descriptive. So, I have changed the column name that are more descriptive. I have also found that dog name some time start with capital letter and other time with lower case. For the consistency, I have changed dog name to lower case.\n",
    "In the confident column, the result was in six digit, I have converted that to three digit because six digit is too long. To get the idea three digit is just unambiguously represents that. Twitter id in all three datasets was in integer datatype. I have converted that to object type. Tweet_enhanced dataset contains a column timestamp that was in object type so I converted to datetime type. In the source column, source contain whole url with html tag. So, I have removed the html tag. I also have drop some column from this dataset because those column does not contain much information. The dog stage was recorded in four columns so I have unpivoted that and made one column for dog stage. The dataset that downloaded from twitter (tweet_count) API was quite clean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have merged tweet_count and twitter enhanced dataset together. after that I have saved the merged file as twitter_archive_master. Image prediction dataset keep separate though. Reason for that , to use this dataset it require more cleaning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
